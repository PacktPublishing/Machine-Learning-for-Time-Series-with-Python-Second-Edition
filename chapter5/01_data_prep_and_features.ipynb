{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277cd65-bde4-4f4d-96ec-51e69c2ef32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578254dc-d85e-4d62-8ff4-1e6d91ebe4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/352/online+retail.zip\"\n",
    "\n",
    "r = requests.get(url)\n",
    "r.raise_for_status()  # check that the download was successful\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "    z.extractall(\".\")  # extract into current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b362dc-2f2e-49db-8932-274e23535302",
   "metadata": {},
   "source": [
    "## Loading and Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5caf54-abdc-4815-9d69-4192782a6647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from Online Retail.xlsx, shape: (541909, 8)\n",
      "Preview:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  Sales  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  15.30  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  20.34  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  22.00  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  20.34  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  20.34  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of possible file paths\n",
    "file_paths = [\n",
    "    \"Online Retail.xlsx\"\n",
    "]\n",
    "\n",
    "# Load the first existing file\n",
    "for path in file_paths:\n",
    "    try:\n",
    "        if path.endswith('.xlsx'):\n",
    "            df_raw = pd.read_excel(path, sheet_name=0)  # read the first sheet\n",
    "        else:\n",
    "            df_raw = pd.read_csv(path, low_memory=False)\n",
    "        print(f\"Loaded data from {path}, shape: {df_raw.shape}\")\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "else:\n",
    "    raise FileNotFoundError(\"None of the UCI Online Retail II files were found.\")\n",
    "\n",
    "# Convert InvoiceDate to datetime\n",
    "df_raw['InvoiceDate'] = pd.to_datetime(df_raw['InvoiceDate'])\n",
    "\n",
    "# Optional: filter out canceled transactions (InvoiceNo starting with 'C')\n",
    "df_raw = df_raw[~df_raw['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "\n",
    "# Create Sales column (equivalent to Rossmann Sales)\n",
    "df_raw['Sales'] = df_raw['Quantity'] * df_raw['UnitPrice']\n",
    "\n",
    "print(\"Preview:\")\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a98564-f041-481e-9f7c-5d0f3599bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The UCI dataset has InvoiceDate, Quantity, UnitPrice, Customer ID, Country, StockCode, Description\n",
    "df_raw['InvoiceDate'] = pd.to_datetime(df_raw['InvoiceDate'])\n",
    "# Normalize column names\n",
    "df_raw.columns = [c.strip() for c in df_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa1e134-1092-4629-9adf-8a6edcc445fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some InvoiceNo start with 'C' indicating cancellations; also remove negative quantities\n",
    "if 'InvoiceNo' in df_raw.columns:\n",
    "    df_raw = df_raw[~df_raw['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "\n",
    "# Filter quantity > 0 and unitprice >= 0\n",
    "df_raw = df_raw[(df_raw['Quantity'] > 0) & (df_raw['UnitPrice'] >= 0)].copy()\n",
    "\n",
    "# Create Revenue column\n",
    "df_raw['Revenue'] = df_raw['Quantity'] * df_raw['UnitPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f35b26aa-ba36-450b-bfd7-fc7c8f1437e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Kingdom share: 91.53%\n"
     ]
    }
   ],
   "source": [
    "# Option A: use Country as Store\n",
    "df_raw['Store'] = df_raw['Country']\n",
    "\n",
    "\n",
    "# Optional: if UK dominates, you may want to downsample or split UK by top SKUs as pseudo-stores\n",
    "# Example: create pseudo-stores within UK by assigning top N StockCodes to separate store labels\n",
    "uk_share = df_raw['Country'].value_counts(normalize=True).get('United Kingdom', 0)\n",
    "print(f\"United Kingdom share: {uk_share:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59e6a558-3fcc-47b7-bd1c-ad763bdae0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily aggregated shape: (1554, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>358.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2010-12-08</td>\n",
       "      <td>258.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2010-12-17</td>\n",
       "      <td>415.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>7154.38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2011-01-10</td>\n",
       "      <td>81.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store       Date    Sales  Transactions  Customers  Lines\n",
       "0  Australia 2010-12-01   358.25             1          1     14\n",
       "1  Australia 2010-12-08   258.90             1          1      8\n",
       "2  Australia 2010-12-17   415.70             1          1     10\n",
       "3  Australia 2011-01-06  7154.38             2          2     48\n",
       "4  Australia 2011-01-10    81.60             1          1      1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 'Date' column at daily frequency\n",
    "df_raw['Date'] = df_raw['InvoiceDate'].dt.floor('d')\n",
    "\n",
    "# Create Sales column if not done yet\n",
    "df_raw['Sales'] = df_raw['Quantity'] * df_raw['UnitPrice']\n",
    "\n",
    "# Define pseudo-store: either Country or specific high-volume StockCodes\n",
    "df_raw['Store'] = df_raw['Country']  # simplest approach\n",
    "\n",
    "# Aggregate daily\n",
    "daily = df_raw.groupby(['Store', 'Date']).agg(\n",
    "    Sales=('Sales', 'sum'),\n",
    "    Transactions=('InvoiceNo', 'nunique'),\n",
    "    Customers=('CustomerID', lambda x: x.nunique()),  # fixed column name\n",
    "    Lines=('StockCode', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Fallback if many missing CustomerIDs\n",
    "if daily['Customers'].isna().mean() > 0.5:\n",
    "    daily['Customers'] = daily['Transactions']\n",
    "\n",
    "print('Daily aggregated shape:', daily.shape)\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "368d8143-64cc-4a53-8a0c-c953b3e42f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/dpjs6jdx52xgnf97mcsn19240000gp/T/ipykernel_44047/1242461860.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# Open flag\n",
    "daily['Open'] = (daily['Sales'] > 0).astype(int)\n",
    "\n",
    "# Compute daily avg unit price per Store\n",
    "price_df = (\n",
    "    df_raw.groupby(['Store', 'Date'], as_index=False)\n",
    "    .apply(lambda g: pd.Series({\n",
    "        'DailyAvgPrice': g['Revenue'].sum() / g['Quantity'].sum() if g['Quantity'].sum() > 0 else np.nan\n",
    "    }))\n",
    ")\n",
    "\n",
    "# Merge to daily\n",
    "daily = daily.merge(price_df, on=['Store', 'Date'], how='left')\n",
    "\n",
    "# Compute rolling 30-day median per store efficiently\n",
    "daily.sort_values(['Store', 'Date'], inplace=True)\n",
    "daily['Price30dMedian'] = (\n",
    "    daily.groupby('Store')['DailyAvgPrice']\n",
    "    .apply(lambda x: x.shift(1).rolling(window=30, min_periods=7).median())\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Promo flag\n",
    "daily['Promo'] = ((daily['DailyAvgPrice'] < 0.95 * daily['Price30dMedian']) & daily['DailyAvgPrice'].notna()).astype(int)\n",
    "\n",
    "# Fill NaNs safely\n",
    "daily['DailyAvgPrice'] = daily['DailyAvgPrice'].fillna(daily['DailyAvgPrice'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9d4064d-6664-4548-aeff-499b88a91fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily['Year'] = daily['Date'].dt.year\n",
    "daily['Month'] = daily['Date'].dt.month\n",
    "daily['Day'] = daily['Date'].dt.day\n",
    "# ISO week\n",
    "daily['WeekOfYear'] = daily['Date'].dt.isocalendar().week.astype(int)\n",
    "# Monday=0\n",
    "daily['DayOfWeek'] = daily['Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7cb456a-6dc4-466f-8e44-c51466369058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.europe import UnitedKingdom\n",
    "\n",
    "# We'll flag UK holidays for the United Kingdom store; for other countries, this block can be extended\n",
    "cal = UnitedKingdom()\n",
    "\n",
    "# Create IsHoliday default 0\n",
    "daily['IsHoliday'] = 0\n",
    "\n",
    "uk_mask = daily['Store'] == 'United Kingdom'\n",
    "if uk_mask.any():\n",
    "    uk_dates = daily.loc[uk_mask, 'Date'].dt.date.unique()\n",
    "    uk_holidays = set(d for d, _ in cal.holidays(2009) + cal.holidays(2010) + cal.holidays(2011))\n",
    "    # Workalendar returns list of tuples, so above is illustrative; safer to generate per-year\n",
    "    holidays_all = set()\n",
    "    for y in daily['Year'].unique():\n",
    "        try:\n",
    "            holidays_all.update([d for d, _ in cal.holidays(y)])\n",
    "        except Exception:\n",
    "            pass\n",
    "    daily.loc[uk_mask, 'IsHoliday'] = daily.loc[uk_mask, 'Date'].dt.date.isin(holidays_all).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0f400a-c65c-4349-97d6-87d413cb2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create store-level metadata using historical activity\n",
    "store_meta = df_raw.groupby('Store').agg(\n",
    "    NumUniqueSKUs=('StockCode', 'nunique'),\n",
    "    TotalRevenue=('Revenue', 'sum'),\n",
    "    FirstSale=('Date', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Assortment: bin NumUniqueSKUs\n",
    "store_meta['Assortment'] = pd.qcut(store_meta['NumUniqueSKUs'].rank(method='first'), q=3, labels=['a', 'b', 'c'])\n",
    "\n",
    "# StoreType: map by region heuristic from country name (simple)\n",
    "def map_store_type(country):\n",
    "    eu = ['United Kingdom', 'France', 'Germany', 'Spain', 'Netherlands', 'Belgium', 'Ireland', 'Portugal', 'Italy']\n",
    "    if country in eu:\n",
    "        return 'a'\n",
    "    if 'United' in country or 'Kingdom' in country:\n",
    "        return 'a'\n",
    "    if country == 'EIRE' or country == 'Ireland':\n",
    "        return 'b'\n",
    "    return 'c'\n",
    "\n",
    "store_meta['StoreType'] = store_meta['Store'].apply(map_store_type)\n",
    "\n",
    "# CompetitionDistance synthetic: use inverse of TotalRevenue as \"distance\" (smaller revenue -> farther)\n",
    "max_rev = store_meta['TotalRevenue'].max()\n",
    "store_meta['CompetitionDistance'] = (max_rev - store_meta['TotalRevenue']) / max_rev * 100000\n",
    "\n",
    "# Merge store_meta into daily\n",
    "daily = daily.merge(store_meta[['Store', 'StoreType', 'Assortment', 'CompetitionDistance']], on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da0289cf-db81-4ac1-94bc-f016b5abfb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/dpjs6jdx52xgnf97mcsn19240000gp/T/ipykernel_44047/2623317427.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  daily.groupby('Store').apply(lambda g: g.fillna(method='bfill').fillna(method='ffill'))\n",
      "/var/folders/zs/dpjs6jdx52xgnf97mcsn19240000gp/T/ipykernel_44047/2623317427.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily.groupby('Store').apply(lambda g: g.fillna(method='bfill').fillna(method='ffill'))\n"
     ]
    }
   ],
   "source": [
    "# Sort first\n",
    "daily.sort_values(['Store', 'Date'], inplace=True)\n",
    "\n",
    "lags = [1, 7]\n",
    "for lag in lags:\n",
    "    daily[f'Sales_lag_{lag}'] = daily.groupby('Store')['Sales'].shift(lag)\n",
    "\n",
    "windows = [7, 28]\n",
    "for window in windows:\n",
    "    daily[f'Sales_rolling_mean_{window}'] = daily.groupby('Store')['Sales'].transform(lambda x: x.shift(1).rolling(window=window, min_periods=1).mean())\n",
    "    daily[f'Sales_rolling_std_{window}'] = daily.groupby('Store')['Sales'].transform(lambda x: x.shift(1).rolling(window=window, min_periods=1).std())\n",
    "\n",
    "# Fill NaNs conservatively: forward fill within store then global median\n",
    "daily.groupby('Store').apply(lambda g: g.fillna(method='bfill').fillna(method='ffill'))\n",
    "\n",
    "# After groupwise fills, remaining NaNs -> fill with global median or 0\n",
    "num_cols = daily.select_dtypes(include=[np.number]).columns.tolist()\n",
    "daily[num_cols] = daily[num_cols].fillna(daily[num_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2caf0829-b551-42ca-8d9c-fbaa9bbb8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclical(df, col, max_val):\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
    "    return df\n",
    "\n",
    "daily = encode_cyclical(daily, 'DayOfWeek', 7)\n",
    "daily = encode_cyclical(daily, 'Month', 12)\n",
    "daily = encode_cyclical(daily, 'Day', 31)\n",
    "daily = encode_cyclical(daily, 'WeekOfYear', 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "027de7b9-29f5-4d61-951f-0937ea03cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition duration (synthetic) - example: use FirstSale as proxy for competitor absent/present\n",
    "# For UCI we don't have CompetitionOpenSince â€” create zeros\n",
    "daily['CompetitionDurationMonths'] = 0.0\n",
    "\n",
    "# Promo on weekend interaction\n",
    "daily['IsWeekend'] = daily['DayOfWeek'].isin([5,6]).astype(int)\n",
    "daily['PromoOnWeekend'] = daily['Promo'] * daily['IsWeekend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3556b124-c5fe-40cc-8282-c212c33e5b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to processed_train_uci.parquet\n",
      "Saved synthetic store metadata to country_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = ['DailyAvgPrice', 'Price30dMedian']\n",
    "daily.drop(columns=[c for c in cols_to_drop if c in daily.columns], inplace=True, errors='ignore')\n",
    "\n",
    "# Save processed parquet\n",
    "out_fp = 'processed_train_uci.parquet'\n",
    "daily.to_parquet(out_fp, index=False)\n",
    "print('Saved processed data to', out_fp)\n",
    "\n",
    "# Also save store metadata for teaching merge examples\n",
    "store_meta.to_csv('country_metadata.csv', index=False)\n",
    "print('Saved synthetic store metadata to country_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1543ec-e4ce-4c91-8d6c-7c33b2e7ae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
